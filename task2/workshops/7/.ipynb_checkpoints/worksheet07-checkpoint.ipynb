{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 7\n",
    "## Support Vector Machines\n",
    "***\n",
    "This worksheet consists of two parts:\n",
    "\n",
    "1. **SVM hyperparameters**: we explore the effect of the penalty parameter and kernel\n",
    "2. **Primal vs. dual**: we examine the computational efficiency of the primal and dual formulations in two different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SVM hyperparameters\n",
    "In this section, we'll explore how the SVM hyperparameters (i.e. the penalty parameter, the kernel, and any kernel parameters) affect the decision surface.\n",
    "\n",
    "#### 1.1 Data set\n",
    "To make visualisation and training easy, we'll consider a small binary classification data set called `cats.csv` (available from the LMS). \n",
    "It contains observations for 150 cats.\n",
    "There are two features: heart and body weight measured in kilograms.\n",
    "    The target variable is the sex of the cat (we encode 'male' as`-1` and 'female as `+1`).\n",
    "\n",
    "\\[Note: the data set originates from the following paper: R. A. Fisher (1947) _The analysis of covariance method for the relation between a part and the whole_, Biometrics **3**, 65–68\\]\n",
    "\n",
    "Ensure that `cats.csv` is located in the same directory as this notebook, then run the following code block to read the CSV file using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('cats.csv')\n",
    "full_df.SEX = full_df.SEX.map({'M': -1, 'F': 1})\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train/test sets so that we can evaluate our trained SVM.\n",
    "(Note that this is likely to be unreliable for such a small data set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code block below to standardise the features (heart and body weight), so that each feature has zero mean/unit variance.\n",
    "(Hint: use the built-in `sklearn.preprocessing.StandardScaler`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = ... # fill in\n",
    "Y_train = ... # fill in\n",
    "\n",
    "X_test = ... # fill in\n",
    "Y_test = ... # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the data. Notice that it's not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[Y_train==1,0], X_train[Y_train==1,1], label=\"Female (Y=1)\", c='r', edgecolors='k')\n",
    "plt.scatter(X_train[Y_train==-1,0], X_train[Y_train==-1,1], label=\"Male (Y=-1)\", c='b', edgecolors='k')\n",
    "plt.xlabel(\"Heart weight\")\n",
    "plt.ylabel(\"Body weight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Parameter grid search\n",
    "Since the data is clearly not linearly separable, we're going to fit a kernelised SVM.\n",
    "To do this, we'll use the `sklearn.svm.SVC` class, which is a wrapper for the popular LIBSVM library.\n",
    "For reference, note that LIBSVM solves the dual problem using a variant of SMO (sequential minimal optimisation).\n",
    "The corresponding primal problem is as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{\\mathbf{w}, b, \\xi} \\phantom{=} & \\frac{1}{2} \\mathbf{w}^T \\mathbf{w} + C \\sum_{i = 1}^{n} \\xi_i \\\\\n",
    "      \\mathrm{subject~to} \\phantom{=} & y_{i}(\\mathbf{w}^T \\cdot \\phi(\\mathbf{x_i}) + b) \\geq 1 - \\xi_i \\\\\n",
    "                          \\phantom{=} & \\xi_i \\geq 0 \\ \\forall i\n",
    "\\end{align}\n",
    "$$\n",
    "Here $C$ is the penalty parameter, $\\mathbf{w}$ are the weights, $b$ is the bias and $\\phi$ is a mapping to a higher dimensional space---related to the kernel through $K(\\mathbf{x}_i, \\mathbf{x}_j) = \\langle \\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j) \\rangle$.\n",
    "For now, we'll use the radial basis function (RBF) kernel, which is parameterised in terms of $\\gamma$ as follows:\n",
    "$$\n",
    "K(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp(-\\gamma \\|\\mathbf{x}_i - \\mathbf{x}_j\\|^2)\n",
    "$$\n",
    "\n",
    "Returning to our classification problem: it's unclear how to set appropriate values for $C$ and $\\gamma$ (named `C` and `gamma` in `sklearn`).\n",
    "A simple way around this is to do an exhaustive grid search.\n",
    "Below we define an evenly-spaced grid in log-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 5, 8)\n",
    "gamma_range = np.logspace(-6, 1, 16)\n",
    "\n",
    "# Visualise the grid\n",
    "xx, yy = np.meshgrid(C_range, gamma_range)\n",
    "plt.plot(xx, yy, 'ko')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the grid search, we'll use the built-in `sklearn.model_selection.GridSearchCV` class.\n",
    "It evaluates the model for each combination of parameter values using cross validation, and selects the combination with the best score.\n",
    "\n",
    "We'll use `StratifiedShuffleSplit` for cross validation (it effectively generates bootstrap samples from the training data, while preserving the class ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=30, test_size=0.1, random_state=1)\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid={'gamma': gamma_range, 'C': C_range}, cv=cv)\n",
    "grid.fit(X_train, Y_train)\n",
    "print(\"The best parameters are {0.best_params_} with a score of {0.best_score_:.3g}\".format(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why aren't we using k-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualise the cross validation accuracy over the grid of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid.cv_results_['mean_test_score'].reshape(C_range.size, gamma_range.size)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(scores)\n",
    "plt.colorbar(shrink=0.7)\n",
    "plt.xticks(np.arange(len(gamma_range)), [\"%.2e\" % gamma for gamma in gamma_range], rotation=90)\n",
    "plt.yticks(np.arange(len(C_range)), [\"%1.e\" % C for C in C_range])\n",
    "plt.title('Cross validation accuracy')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Interpret this plot. Is there a clear winning combination of parameters?\n",
    "\n",
    "Now that we've found the \"best\" parameters, let's fit the SVM on the entire training set (without cross-validation) so that we can evaluate on the test set. \n",
    "\n",
    "(Note: we actually fit all parameter combinations, as they're needed for a plot generated below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {(C, gamma) : SVC(C=C, gamma=gamma, kernel='rbf').fit(X_train, Y_train) \n",
    "               for C in C_range\n",
    "               for gamma in gamma_range}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code block below to compute the test accuracy.\n",
    "\n",
    "**Question:** How does this compare to the cross validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = (grid.best_params_[\"C\"], grid.best_params_[\"gamma\"])\n",
    "best_svm = classifiers[best_params]\n",
    "best_acc = ... # fill in\n",
    "print(\"The SVM with parameters C={0[0]:.3g}, gamma={0[1]:.3g} has test accuracy {1:.3g}.\".format(best_params, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we visualise the decision functions for all parameter combinations (double-click output to expand to 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(C_range.size, gamma_range.size, figsize=(50,20))\n",
    "border = 0.2\n",
    "\n",
    "# Build meshgrid over the feature space\n",
    "X_min = np.amin(X_train, axis=0)\n",
    "X_max = np.amax(X_train, axis=0)\n",
    "xx, yy = np.meshgrid(np.linspace(X_min[0] - border, X_max[0] + border, 100), \n",
    "                     np.linspace(X_min[1] - border, X_max[1] + border, 100))\n",
    "\n",
    "# Plot training data + decision function for all feature combinations\n",
    "for (i, C) in enumerate(C_range):\n",
    "    for (j, gamma) in enumerate(gamma_range):\n",
    "        clf = classifiers[(C, gamma)]\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        axarr[i,j].set_title(\"gamma={0.gamma:.3g}; C={0.C:.3g}\".format(clf), \n",
    "                           size='medium')\n",
    "\n",
    "        axarr[i,j].pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "        axarr[i,j].scatter(X_train[Y_train==1,0], X_train[Y_train==1,1], c='r', edgecolors='k')\n",
    "        axarr[i,j].scatter(X_train[Y_train==-1,0], X_train[Y_train==-1,1], c='b', edgecolors='k')\n",
    "        axarr[i,j].set_xticks([])\n",
    "        axarr[i,j].set_yticks([])\n",
    "        axarr[i,j].axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Explain how `gamma` and `C` affect the decision surface qualitatively.\n",
    "\n",
    "**Extension activity:** Re-run this section using a different kernel (e.g. the built-in polynomial kernel or a custom kernel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Primal vs dual\n",
    "In this section, we'll compare the computational efficiency of two linear SVM implementations: in the primal and dual formulations.\n",
    "We'll use the `sklearn.svm.LinearSVC` class, which is a wrapper for LIBLINEAR (from the same authors as LIBSVM, but optimised for the linear kernel).\n",
    "\n",
    "_Note: LIBLINEAR does not implement a primal-based method for the regular hinge loss SVM.\n",
    "Hence, we'll work with the squared-hinge loss SVM, for which both primal- and dual-based methods are available._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data set\n",
    "Below we define a random generator for synthetic binary classification data sets.\n",
    "Our reasons for doing this are twofold:\n",
    "* we should compare the SVM implementations on a variety of data sets (a single data set may favour one of the methods)\n",
    "* we should ensure the same sequence of data sets are used for each benchmark (by setting the random seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "class DataGenerator(object):\n",
    "    def __init__(self, n_instances, n_features, n_datasets, random_seed=1):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        =========\n",
    "        n_instances : int\n",
    "            number of instances\n",
    "        n_features : int\n",
    "            number of features\n",
    "        n_datasets : int\n",
    "            number of data sets to generate before stopping\n",
    "        \"\"\"\n",
    "        self.ctr = 0\n",
    "        self.n_datasets = n_datasets\n",
    "        self.n_instances = n_instances\n",
    "        self.n_features = n_features\n",
    "        self.rng = np.random.RandomState(random_seed)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        =======\n",
    "        X : numpy array, shape: (n_instances, n_features)\n",
    "            feature matrix\n",
    "        Y : numpy array, shape: (n_instances,)\n",
    "            target class labels relative to X\n",
    "        \"\"\"\n",
    "        if (self.ctr < self.n_datasets):\n",
    "            self.ctr += 1\n",
    "            return make_classification(n_samples=self.n_instances, n_features=self.n_features, \n",
    "                                       n_informative=10, n_classes=2, n_clusters_per_class=3, \n",
    "                                       flip_y=0.01, class_sep=0.8, random_state=self.rng)\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Benchmark\n",
    "Below we define a function that takes a `LinearSVC` instance as input (either the dual or primal) and runs a benchmark.\n",
    "The benchmark is to fit the SVM on all of the data sets produced by a `DataGenerator` instance.\n",
    "We compute the mean training time with standard error, as well as the mean accuracy (over all data sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf, data_generator):\n",
    "    \"\"\"\n",
    "    Benchmarks a classifier.\n",
    "    \n",
    "    clf : a sklearn classifier\n",
    "    data_generator : a DataGenerator instance\n",
    "    \"\"\"\n",
    "    traintimes = np.empty(data_generator.n_datasets, dtype=np.float)\n",
    "    accuracies = np.empty(data_generator.n_datasets, dtype=np.float)\n",
    "    for (i, (X, Y)) in enumerate(data_generator):\n",
    "        start = timer()\n",
    "        clf.fit(X,Y)\n",
    "        end = timer()\n",
    "        traintimes[i] = end - start\n",
    "        accuracies[i] = clf.score(X, Y)\n",
    "    \n",
    "    mean_traintime = np.mean(traintimes)\n",
    "    stderr_traintime = np.std(traintimes)/np.sqrt(traintimes.size)\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    \n",
    "    print(\"Training time: {:.3g} ± {:.1g} s. Mean accuracy: {:.3g}.\".format(mean_traintime, stderr_traintime, mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the primal and dual `LinearSVC` instances and then run the benchmarks in different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_primal = LinearSVC(dual=False, C=1.0)\n",
    "clf_dual = LinearSVC(dual=True, C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_instances >> n_features, primal\n",
    "benchmark(...) # fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_instances >> n_features, dual\n",
    "benchmark(...) # fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features >> n_instances, primal\n",
    "benchmark(...) # fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features >> n_instances, dual\n",
    "benchmark(...) # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you observe?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
